Notes:
Use an adapted version of the Elo rating system which takes into account how
well the winning team outperformed their opponents. A team with a much higher
rating would be expected to win by more than one point, but teams closer in
ratings should see games closer to a 1-goal difference.
(Edit: in the basketball rating system where I used the adapted system I'm
looking at, if a high-rated team didn't win by a certain margin, their score
would not increase, but if they won while being less than their expected score,
they still wouldn't lose points. Perhaps this might not be suitable for pro
teams and their scores should always be adjusted?)

In the NHL, there are no ties, so the minimum difference between goals is 1.
(Edit: Apparently, in previous seasons they did end with ties. Not a problem,
an equally matched team is expected to tie.)

Pre-season and post-season games should see smaller changes in rating. What
should the weights be?
(Edit: pre-season games should see more change than the regular season, and
post-season games less than than the regular season.)

At the beginning of new seasons, inflate the sigma for each team to account
for new team compositions (coaches, players, whatever) and then begin to
reduce to normal levels. This gives the opportunities for underpeforming teams
in a previous season to not be penalized too heavily in the current season.
Meaning, they may have improved. This is also requires that strong teams would
need to maintain their strength and aren't given a free pass.

I couldn't figure out how to tell whether the games went to overtime/shootout.

Consider having separate ratings based on:
  1. Goals, i.e. the actual outcome of the game
  2. Shots
  3. Difference between takeaways and giveaways
The last two might, I hope, be useful as some kind of ancillary ratings.

Make an R Shiny app to show the ratings across time.

Set up a daily cron job to get the latest data.

Pull the game schedule to see upcoming match ups and the teams ratings. This
can be used as something of a prediction method. Can I use the schedule to get
the actual date the game was played on?

For ranges, I'm thinking a difference of 200 we should see more overtime and
shootout games. For every 400 point difference, say the expected goal difference
increases by one. So a team with rating 1000 facing a team with rating 1800
is expected to lose by 2 goals. But I'd like to keep the variance high enough,
so maybe instead of losing by 2, they might lose by 1 to 3 goals. Hockey has
a large luck component to it, so this should be taken into account perhaps by
not shrinking the sigma too fast toward zero, or to some higher fixed amount.
(Edit: it seems accounting for the skill range could be done by using the
Glicko/Glicko-2 rating system https://en.wikipedia.org/wiki/Glicko_rating_system)

Not all seasons had pre-season games.

The data begin after the 2004-2005 lockout. In the following season, the draft
order was randomized. There was some weighting, but I'm going to assume this
point marks a suitable starting point to treat each team as equal by assigning
the same initial rating across teams. When Vegas is introduced, I'll likely
give them the average rating across the league.

Show rating change as result of latest game outcome.

Forgot about teams being disbanded or moving locations. In 1996, the Jets moved
to Phoenix and became the Pheonix Coyotes. In 2014, they were renamed the
Arizona Coyotes. The Pheonix Coyotes and the Arizona Coyotes have different IDs
in the API. They will be treated as a new team. In 2011, the Atlanta Thrashers
became the Winnipeg Jets. They will also be treated as a new team. So basically,
regardless of how a team (with a new ID) enters into the league, they will be
treated just as any other new team, such as VGK in 2017.
